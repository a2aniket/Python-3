{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Recognition â€“ Unlock Your Application With Your Face!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 1 - Create Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of your face from webcam input\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (200, 200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = './faces/user/' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained sucessefully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Get the training data we previously made\n",
    "data_path = './faces/user/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "# Create arrays for training data and labels\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "# Open training images in our datapath\n",
    "# Create a numpy array for training data\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "\n",
    "# Create a numpy array for both training data and labels\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "# Initialize facial recognizer\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "# NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "\n",
    "# Let's train our model \n",
    "model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print(\"Model trained sucessefully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Run Our Facial Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    image, face = face_detector(frame)\n",
    "    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Pass face to prediction model\n",
    "        # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "        results = model.predict(face)\n",
    "        \n",
    "        if results[1] < 500:\n",
    "            confidence = int( 100 * (1 - (results[1])/400) )\n",
    "            display_string = str(confidence) + '% Confident it is User'\n",
    "            \n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "        \n",
    "        if confidence > 75:\n",
    "            cv2.putText(image, \"Unlocked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "        else:\n",
    "            cv2.putText(image, \"Locked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"Locked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "        \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "lst=[]\n",
    "start_time=time.time()\n",
    "elapsed_time=time.time()\n",
    "# Collect 100 samples of your face from webcam input\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        start_time = time.time()\n",
    "        face = cv2.resize(face_extractor(frame), (200, 200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(time.clock()), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        print(\"Face not found\")\n",
    "        elapsed_time = time.time() - start_time\n",
    "        lst.append(elapsed_time)\n",
    "        seconds=0\n",
    "        time.sleep(1)\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        \n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.06690478324890137,\n",
       " 1.122706413269043,\n",
       " 0.12368535995483398,\n",
       " 0.06865954399108887]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(lst,bins=20,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "datetime.datetime.now()-time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.002671003341675\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "time.sleep(5)\n",
    "elapsed_time = time.time() - start_time\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
